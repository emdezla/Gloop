{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "input_file = 'datasets/raw/OhioT1DM/563-ws-testing.xml'\n",
    "output_file = 'datasets/processed/563-test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_type):\n",
    "    data = []\n",
    "    if data_type in ['glucose_level', 'finger_stick', 'basal', 'basis_heart_rate', \n",
    "                        'basis_gsr', 'basis_skin_temperature', 'basis_air_temperature', 'basis_steps']:\n",
    "        for event in root.findall(f'.//{data_type}/event'):\n",
    "            ts_str = event.get('ts')\n",
    "            ts = datetime.strptime(ts_str, '%d-%m-%Y %H:%M:%S')\n",
    "            if data_type in ['basal', 'basis_gsr', 'basis_skin_temperature', 'basis_air_temperature']:\n",
    "                value = float(event.get('value'))\n",
    "            else:\n",
    "                value = int(event.get('value'))\n",
    "            data.append([np.datetime64(ts), value])\n",
    "    elif data_type == 'temp_basal':\n",
    "        for event in root.findall(f'.//{data_type}/event'):\n",
    "            ts_begin_str = event.get('ts_begin') or event.get('tbegin')\n",
    "            ts_end_str   = event.get('ts_end') or event.get('tend')\n",
    "            ts_begin = datetime.strptime(ts_begin_str, '%d-%m-%Y %H:%M:%S') if ts_begin_str else None\n",
    "            ts_end   = datetime.strptime(ts_end_str, '%d-%m-%Y %H:%M:%S') if ts_end_str else None\n",
    "            value = float(event.get('value'))\n",
    "            data.append([np.datetime64(ts_begin), np.datetime64(ts_end), value])\n",
    "    elif data_type == 'bolus':\n",
    "        for event in root.findall(f'.//{data_type}/event'):\n",
    "            ts_begin_str = event.get('ts_begin')\n",
    "            ts_end_str   = event.get('ts_end')\n",
    "            ts_begin = datetime.strptime(ts_begin_str, '%d-%m-%Y %H:%M:%S')\n",
    "            ts_end   = datetime.strptime(ts_end_str, '%d-%m-%Y %H:%M:%S')\n",
    "            dose = float(event.get('dose'))\n",
    "            data.append([np.datetime64(ts_begin), np.datetime64(ts_end), dose])\n",
    "    elif data_type == 'meal':\n",
    "        for event in root.findall(f'.//{data_type}/event'):\n",
    "            ts_str = event.get('ts')\n",
    "            ts = datetime.strptime(ts_str, '%d-%m-%Y %H:%M:%S')\n",
    "            meal_type = event.get('type')\n",
    "            carbs = int(event.get('carbs'))\n",
    "            data.append([np.datetime64(ts), meal_type, carbs])\n",
    "    elif data_type == 'exercise':\n",
    "        for event in root.findall(f'.//{data_type}/event'):\n",
    "            ts_str = event.get('ts')\n",
    "            ts = datetime.strptime(ts_str, '%d-%m-%Y %H:%M:%S')\n",
    "            intensity = int(event.get('intensity'))\n",
    "            duration = int(event.get('duration'))  # duration in minutes\n",
    "            ts_end = ts + timedelta(minutes=duration)\n",
    "            data.append([np.datetime64(ts), np.datetime64(ts_end), intensity])\n",
    "    return np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.parse(input_file).getroot()\n",
    "\n",
    "glucose_level = parse_data('glucose_level') # continuous data\n",
    "finger_stick = parse_data('finger_stick') #sparse data\n",
    "basal = parse_data('basal') #sparse data \n",
    "basis_heart_rate = parse_data('basis_heart_rate') #continuous data\n",
    "basis_gsr = parse_data('basis_gsr') #continuous data\n",
    "basis_skin_temperature = parse_data('basis_skin_temperature') #continuous data\n",
    "basis_air_temperature = parse_data('basis_air_temperature') #continuous data\n",
    "basis_steps = parse_data('basis_steps') #continuous data\n",
    "temp_basal = parse_data('temp_basal') #Tb #Te #dose\n",
    "bolus = parse_data('bolus') #Tb #Te #dose #carb_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = {\n",
    "    'glucose_level': glucose_level,\n",
    "    'finger_stick': finger_stick,\n",
    "    'basal': basal,\n",
    "    'basis_heart_rate': basis_heart_rate,\n",
    "    'basis_gsr': basis_gsr,\n",
    "    'basis_skin_temperature': basis_skin_temperature,\n",
    "    'basis_air_temperature': basis_air_temperature,\n",
    "    'basis_steps': basis_steps\n",
    "}\n",
    "\n",
    "# Convert each measurement array to a DataFrame with proper datetime conversion.\n",
    "dfs = {}\n",
    "global_min = None\n",
    "global_max = None\n",
    "\n",
    "for name, arr in measurements.items():\n",
    "    df = pd.DataFrame(arr, columns=['timestamp', name])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "    dfs[name] = df\n",
    "    \n",
    "    # Update the global min and max timestamps.\n",
    "    current_min = df['timestamp'].min()\n",
    "    current_max = df['timestamp'].max()\n",
    "    if global_min is None or current_min < global_min:\n",
    "        global_min = current_min\n",
    "    if global_max is None or current_max > global_max:\n",
    "        global_max = current_max\n",
    "\n",
    "# Force the global start to midnight.\n",
    "global_start = global_min.normalize()\n",
    "global_end = global_max\n",
    "\n",
    "# Create a perfect timestamp index with a 5-minute frequency over the full range.\n",
    "perfect_index = pd.date_range(start=global_start, end=global_end, freq='5min')\n",
    "df_perfect = pd.DataFrame({'perfect_timestamp': perfect_index})\n",
    "\n",
    "# Function to perform asof merge for a given measurement DataFrame.\n",
    "def merge_measurement(df_perfect, df_meas, meas_col):\n",
    "    # Backward merge: the most recent measurement not after the perfect timestamp.\n",
    "    df_merge = pd.merge_asof(\n",
    "        df_perfect,\n",
    "        df_meas.rename(columns={'timestamp': 'prev_timestamp', meas_col: f'{meas_col}_value'}),\n",
    "        left_on='perfect_timestamp',\n",
    "        right_on='prev_timestamp',\n",
    "        direction='backward'\n",
    "    )\n",
    "    # Forward merge: the earliest measurement not before the perfect timestamp.\n",
    "    df_merge = pd.merge_asof(\n",
    "        df_merge,\n",
    "        df_meas.rename(columns={'timestamp': 'next_timestamp', meas_col: f'{meas_col}_value_next'}),\n",
    "        left_on='perfect_timestamp',\n",
    "        right_on='next_timestamp',\n",
    "        direction='forward'\n",
    "    )\n",
    "    return df_merge\n",
    "\n",
    "# Modified threshold in minutes\n",
    "THRESHOLD = 5\n",
    "\n",
    "# Function to choose the closest measurement timestamp and compute time difference in minutes.\n",
    "def choose_nearest(row):\n",
    "    pt = row['perfect_timestamp']\n",
    "    prev = row.get('prev_timestamp', pd.NaT)\n",
    "    nxt = row.get('next_timestamp', pd.NaT)\n",
    "    \n",
    "    # Both missing.\n",
    "    if pd.isna(prev) and pd.isna(nxt):\n",
    "        return pd.NaT, np.nan\n",
    "    # Only previous exists.\n",
    "    elif pd.isna(nxt):\n",
    "        diff = (pt - prev).total_seconds() / 60.0\n",
    "        if diff < THRESHOLD:\n",
    "            return prev, diff\n",
    "        else:\n",
    "            return pd.NaT, np.nan\n",
    "    # Only next exists.\n",
    "    elif pd.isna(prev):\n",
    "        diff = (nxt - pt).total_seconds() / 60.0\n",
    "        if diff < THRESHOLD:\n",
    "            return nxt, diff\n",
    "        else:\n",
    "            return pd.NaT, np.nan\n",
    "    else:\n",
    "        diff_prev = (pt - prev).total_seconds() / 60.0\n",
    "        diff_next = (nxt - pt).total_seconds() / 60.0\n",
    "        if diff_prev <= diff_next and diff_prev < THRESHOLD:\n",
    "            return prev, diff_prev\n",
    "        elif diff_next < THRESHOLD:\n",
    "            return nxt, diff_next\n",
    "        else:\n",
    "            return pd.NaT, np.nan\n",
    "\n",
    "# Function to choose the measurement value based on the nearest valid timestamp.\n",
    "def choose_value(row, meas_col):\n",
    "    pt = row['perfect_timestamp']\n",
    "    prev = row.get('prev_timestamp', pd.NaT)\n",
    "    nxt = row.get('next_timestamp', pd.NaT)\n",
    "    \n",
    "    # Both missing.\n",
    "    if pd.isna(prev) and pd.isna(nxt):\n",
    "        return np.nan\n",
    "    # Only previous exists.\n",
    "    elif pd.isna(nxt):\n",
    "        diff = (pt - prev).total_seconds() / 60.0\n",
    "        if diff < THRESHOLD:\n",
    "            return row[f'{meas_col}_value']\n",
    "        else:\n",
    "            return np.nan\n",
    "    # Only next exists.\n",
    "    elif pd.isna(prev):\n",
    "        diff = (nxt - pt).total_seconds() / 60.0\n",
    "        if diff < THRESHOLD:\n",
    "            return row[f'{meas_col}_value_next']\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        diff_prev = (pt - prev).total_seconds() / 60.0\n",
    "        diff_next = (nxt - pt).total_seconds() / 60.0\n",
    "        if diff_prev <= diff_next and diff_prev < THRESHOLD:\n",
    "            return row[f'{meas_col}_value']\n",
    "        elif diff_next < THRESHOLD:\n",
    "            return row[f'{meas_col}_value_next']\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "# Start with the perfect index DataFrame and then add new columns for each measurement.\n",
    "df_final = df_perfect.copy()\n",
    "\n",
    "for meas, df_meas in dfs.items():\n",
    "    # Merge the measurement into the perfect index.\n",
    "    df_merge = merge_measurement(df_final[['perfect_timestamp']], df_meas, meas)\n",
    "    \n",
    "    # Apply the function to choose the nearest timestamp and compute the time difference.\n",
    "    res = df_merge.apply(lambda row: pd.Series(choose_nearest(row)), axis=1)\n",
    "    df_merge[f'{meas}_associated_timestamp'] = res.iloc[:, 0]\n",
    "    df_merge[f'{meas}_time_diff_min'] = res.iloc[:, 1]\n",
    "    \n",
    "    # Choose the measurement value using the threshold condition.\n",
    "    df_merge[f'{meas}_final'] = df_merge.apply(lambda row: choose_value(row, meas), axis=1)\n",
    "    \n",
    "    # Add the measurement columns to the final DataFrame.\n",
    "    df_final[meas] = df_merge[f'{meas}_final']\n",
    "    df_final[f'{meas}_time_diff_min'] = df_merge[f'{meas}_time_diff_min']\n",
    "\n",
    "\n",
    "# Forward fill the basal values.\n",
    "df_final['basal'] = df_final['basal'].ffill()\n",
    "# Backward fill the basal values (for the first few rows).\n",
    "df_final['basal'] = df_final['basal'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iob(df, DOA_hours=5, interval_min=5):\n",
    "    \"\"\"\n",
    "    Compute the Insulin On Board (IOB) for each row of the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with columns 'real_basal' (in U/hr) and 'bolus' (in U).\n",
    "        DOA_hours (float): Duration of insulin action in hours.\n",
    "        interval_min (float): Time difference between consecutive rows in minutes.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with an added 'IOB' column.\n",
    "    \"\"\"\n",
    "    # Convert time step to hours\n",
    "    interval_hr = interval_min / 60.0\n",
    "    \n",
    "    # Determine the number of time steps for the duration of insulin action (DOA)\n",
    "    decay_steps = int(DOA_hours / interval_hr)\n",
    "    \n",
    "    # Define a quadratic decay curve (from 1 at time=0 to 0 at time=DOA)\n",
    "    t = np.linspace(0, 1, decay_steps)\n",
    "    decay = 1 - (t**2) * (3 - 2*t)  # smooth quadratic decay\n",
    "    \n",
    "    # Convert the basal rate (U/hr) to basal amount (U) delivered in each interval\n",
    "    basal_amt = df['real_basal'] * interval_hr\n",
    "    \n",
    "    # Use convolution to compute the cumulative effect of past boluses and basal doses\n",
    "    # The convolution automatically sums the contributions from previous time steps weighted by decay.\n",
    "    bolus_contrib = np.convolve(df['bolus'], decay, mode='full')[:len(df)]\n",
    "    basal_contrib = np.convolve(basal_amt, decay, mode='full')[:len(df)]\n",
    "    \n",
    "    # Create a copy of the original DataFrame and add the IOB column\n",
    "    df_out = df.copy()\n",
    "    df_out['IOB'] = bolus_contrib + basal_contrib\n",
    "    \n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the real_basal column as a copy of the forward-filled basal values.\n",
    "df_final['real_basal'] = df_final['basal'].copy()\n",
    "\n",
    "# For each temp_basal episode, overwrite real_basal in that time interval.\n",
    "for row in temp_basal:\n",
    "    t_start = pd.to_datetime(row[0])\n",
    "    t_end   = pd.to_datetime(row[1])\n",
    "    val     = row[2]\n",
    "    mask = (df_final['perfect_timestamp'] >= t_start) & (df_final['perfect_timestamp'] <= t_end)\n",
    "    df_final.loc[mask, 'real_basal'] = val\n",
    "\n",
    "\n",
    "df_final['bolus'] = 0.0\n",
    "\n",
    "# Process each bolus entry.\n",
    "for row in bolus:\n",
    "    t_beg = pd.to_datetime(row[0])\n",
    "    t_end = pd.to_datetime(row[1])\n",
    "    dose  = float(row[2])\n",
    "    \n",
    "    if t_beg == t_end:\n",
    "        # Single data point: find the perfect timestamp that is closest.\n",
    "        diffs = (df_final['perfect_timestamp'] - t_beg).abs()\n",
    "        idx = diffs.idxmin()\n",
    "        # Optionally, you can decide to only assign if the closest point is within a threshold.\n",
    "        df_final.loc[idx, 'bolus'] += dose\n",
    "    else:\n",
    "        # Distributed bolus: find all perfect timestamps in the interval.\n",
    "        mask = (df_final['perfect_timestamp'] >= t_beg) & (df_final['perfect_timestamp'] <= t_end)\n",
    "        count = mask.sum()\n",
    "        if count > 0:\n",
    "            distributed = dose / count\n",
    "            df_final.loc[mask, 'bolus'] += distributed\n",
    "\n",
    "\n",
    "df_with_iob = compute_iob(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_with_iob.drop(columns=['glucose_level_time_diff_min','finger_stick', 'finger_stick_time_diff_min', 'basal',\n",
    "       'basal_time_diff_min', 'basis_heart_rate_time_diff_min', 'basis_gsr',\n",
    "       'basis_gsr_time_diff_min', 'basis_skin_temperature','basis_skin_temperature_time_diff_min',\n",
    "       'basis_air_temperature','basis_air_temperature_time_diff_min', 'basis_steps','basis_steps_time_diff_min'],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives\n",
    "df['glucose_derivative'] = df['glucose_level'].diff()/5  # Difference from previous\n",
    "df['heart_rate_derivative'] = df['basis_heart_rate'].diff()/5\n",
    "\n",
    "# Function to calculate trend (slope over last 30 mins = 6 points)\n",
    "def compute_trend(series, window=6):\n",
    "    trend = []\n",
    "    for i in range(len(series)):\n",
    "        if i < window - 1 or series[i - window + 1:i + 1].isna().any():\n",
    "            trend.append(np.nan)\n",
    "        else:\n",
    "            y = series[i - window + 1:i + 1].values.reshape(-1, 1)\n",
    "            x = np.arange(window).reshape(-1, 1)\n",
    "            model = LinearRegression().fit(x, y)\n",
    "            trend.append(model.coef_[0][0])\n",
    "    return trend\n",
    "\n",
    "\n",
    "# Trend columns\n",
    "df['glucose_trend'] = compute_trend(df['glucose_level'])\n",
    "df['heart_rate_trend'] = compute_trend(df['basis_heart_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={\n",
    "    \"perfect_timestamp\":   \"time\",\n",
    "    \"glucose_level\":       \"glu\",\n",
    "    \"basis_heart_rate\":    \"hr\",\n",
    "    \"real_basal\":          \"basal\",\n",
    "    \"IOB\":                 \"iob\",\n",
    "    \"glucose_derivative\":  \"glu_d\",\n",
    "    \"heart_rate_derivative\": \"hr_d\",\n",
    "    \"glucose_trend\":       \"glu_t\",\n",
    "    \"heart_rate_trend\":    \"hr_t\"\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "features_to_normalize = [\n",
    "    \"glu\", \"glu_d\", \"glu_t\",\n",
    "    \"hr\",  \"hr_d\",  \"hr_t\",\n",
    "    \"iob\", \"basal\", \"bolus\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add hour and hour_norm\n",
    "df[\"hour_day\"] = pd.to_datetime(df[\"time\"]).dt.hour\n",
    "df[\"hour\"] = df[\"hour_day\"] / 24.0\n",
    "\n",
    "# Define episodes by day (daily episodes)\n",
    "df[\"day\"] = pd.to_datetime(df[\"time\"]).dt.date\n",
    "df[\"done\"] = (df[\"day\"] != df[\"day\"].shift(-1)).astype(int)\n",
    "\n",
    "# Drop helper columns if needed\n",
    "df.drop(columns=[\"hour_day\", \"day\"], inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "ordered_columns = [\n",
    "    \"time\",            # Optional timestamp for reference\n",
    "    \"glu\", \"glu_d\", \"glu_t\",\n",
    "    \"hr\", \"hr_d\", \"hr_t\",\n",
    "    \"iob\", \"hour\",  # <- state features\n",
    "    \"basal\", \"bolus\",      # <- action features\n",
    "    \"done\"               # <- episode boundary flag\n",
    "]\n",
    "\n",
    "df = df[ordered_columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
